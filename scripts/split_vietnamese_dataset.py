#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  chia dá»¯ liá»‡u clickbait tiáº¿ng Viá»‡t
Chia theo tá»‰ lá»‡ 7:1.5:1.5 (70%:15%:15%) vá»›i stratification
"""

import json
import os
import pandas as pd
from sklearn.model_selection import train_test_split
from collections import Counter
import argparse
from pathlib import Path

def load_and_analyze_data(file_path):
    """
    Load dá»¯ liá»‡u vÃ  phÃ¢n tÃ­ch cáº¥u trÃºc
    """
    print(f"ğŸ” Äang phÃ¢n tÃ­ch dá»¯ liá»‡u tá»«: {file_path}")
    
    data = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            try:
                item = json.loads(line.strip())
                data.append(item)
                if line_num <= 5:  # In ra 5 dÃ²ng Ä‘áº§u Ä‘á»ƒ kiá»ƒm tra format
                    print(f"DÃ²ng {line_num}: {item}")
            except json.JSONDecodeError as e:
                print(f"âŒ Lá»—i JSON á»Ÿ dÃ²ng {line_num}: {e}")
                continue
    
    print(f"\nğŸ“Š Tá»•ng sá»‘ máº«u: {len(data)}")
    
    # Kiá»ƒm tra cÃ¡c trÆ°á»ng dá»¯ liá»‡u
    if data:
        keys = data[0].keys()
        print(f"ğŸ”‘ CÃ¡c trÆ°á»ng dá»¯ liá»‡u: {list(keys)}")
        
        # XÃ¡c Ä‘á»‹nh trÆ°á»ng label (cÃ³ thá»ƒ lÃ  'label', 'clickbait', 'target', v.v.)
        possible_label_fields = ['label', 'clickbait', 'target', 'class', 'category']
        label_field = None
        
        for field in possible_label_fields:
            if field in keys:
                label_field = field
                break
        
        if not label_field:
            print("âš ï¸  KhÃ´ng tÃ¬m tháº¥y trÆ°á»ng label. CÃ¡c trÆ°á»ng cÃ³ sáºµn:", list(keys))
            return None, None
        
        print(f"ğŸ·ï¸  TrÆ°á»ng label Ä‘Æ°á»£c sá»­ dá»¥ng: '{label_field}'")
        
        # PhÃ¢n tÃ­ch phÃ¢n phá»‘i label
        labels = [item[label_field] for item in data]
        label_counts = Counter(labels)
        print(f"\nğŸ“ˆ PhÃ¢n phá»‘i label:")
        for label, count in label_counts.items():
            percentage = (count / len(data)) * 100
            print(f"  {label}: {count} ({percentage:.1f}%)")
        
        return data, label_field
    
    return None, None

def split_data_stratified(data, label_field, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):
    """
    Chia dá»¯ liá»‡u vá»›i stratification
    """
    print(f"\nğŸ”€ Chia dá»¯ liá»‡u theo tá»‰ lá»‡ {train_ratio*100}%:{val_ratio*100}%:{test_ratio*100}%")
    
    # Táº¡o DataFrame Ä‘á»ƒ dá»… xá»­ lÃ½
    df = pd.DataFrame(data)
    
    # Chia train vs temp (val+test)
    train_data, temp_data = train_test_split(
        df, 
        test_size=(val_ratio + test_ratio), 
        stratify=df[label_field], 
        random_state=42
    )
    
    # Chia temp thÃ nh val vÃ  test
    # Tá»‰ lá»‡ val:test trong temp = val_ratio:(val_ratio+test_ratio) = 0.15:0.15 = 1:1
    relative_test_size = test_ratio / (val_ratio + test_ratio)
    
    val_data, test_data = train_test_split(
        temp_data, 
        test_size=relative_test_size, 
        stratify=temp_data[label_field], 
        random_state=42
    )
    
    print(f"âœ… Káº¿t quáº£ chia:")
    print(f"  Train: {len(train_data)} máº«u ({len(train_data)/len(df)*100:.1f}%)")
    print(f"  Val: {len(val_data)} máº«u ({len(val_data)/len(df)*100:.1f}%)")
    print(f"  Test: {len(test_data)} máº«u ({len(test_data)/len(df)*100:.1f}%)")
    
    # Kiá»ƒm tra phÃ¢n phá»‘i label sau khi chia
    print(f"\nğŸ“Š PhÃ¢n phá»‘i label sau khi chia:")
    for split_name, split_data in [("Train", train_data), ("Val", val_data), ("Test", test_data)]:
        label_counts = Counter(split_data[label_field])
        print(f"  {split_name}:")
        for label, count in label_counts.items():
            percentage = (count / len(split_data)) * 100
            print(f"    {label}: {count} ({percentage:.1f}%)")
    
    return train_data, val_data, test_data

def save_split_data(train_data, val_data, test_data, output_dir="data"):
    """
    LÆ°u dá»¯ liá»‡u Ä‘Ã£ chia vÃ o cÃ¡c folder
    """
    print(f"\nğŸ’¾ LÆ°u dá»¯ liá»‡u vÃ o {output_dir}/")
    
    # Táº¡o cÃ¡c folder
    folders = {
        "train_dtVN": train_data,
        "val_dtVN": val_data, 
        "test_dtVN": test_data
    }
    
    for folder_name, data in folders.items():
        folder_path = Path(output_dir) / folder_name
        folder_path.mkdir(parents=True, exist_ok=True)
        
        # LÆ°u data.jsonl
        data_file = folder_path / "data.jsonl"
        with open(data_file, 'w', encoding='utf-8') as f:
            for item in data.to_dict('records'):
                f.write(json.dumps(item, ensure_ascii=False) + '\n')
        
        print(f"  âœ… {folder_name}/data.jsonl: {len(data)} máº«u")
        
        # Táº¡o truth.jsonl (chá»‰ chá»©a labels)
        truth_file = folder_path / "truth.jsonl"
        with open(truth_file, 'w', encoding='utf-8') as f:
            for item in data.to_dict('records'):
                # TÃ¬m trÆ°á»ng label
                label_field = None
                for field in ['label', 'clickbait', 'target', 'class', 'category']:
                    if field in item:
                        label_field = field
                        break
                
                if label_field:
                    f.write(json.dumps({"truth": item[label_field]}, ensure_ascii=False) + '\n')
        
        print(f"  âœ… {folder_name}/truth.jsonl: {len(data)} labels")

def create_data_demo(train_data, val_data, test_data, output_dir="data", demo_size=100):
    """
    Táº¡o file data_demo.jsonl vá»›i máº«u nhá» Ä‘á»ƒ test
    """
    print(f"\nğŸ¯ Táº¡o file demo vá»›i {demo_size} máº«u má»—i split")
    
    folders = {
        "train_dtVN": train_data,
        "val_dtVN": val_data,
        "test_dtVN": test_data
    }
    
    for folder_name, data in folders.items():
        folder_path = Path(output_dir) / folder_name
        
        # Láº¥y máº«u demo (nhá» hÆ¡n náº¿u khÃ´ng Ä‘á»§)
        demo_data = data.sample(n=min(demo_size, len(data)), random_state=42)
        
        # LÆ°u data_demo.jsonl
        demo_file = folder_path / "data_demo.jsonl"
        with open(demo_file, 'w', encoding='utf-8') as f:
            for item in demo_data.to_dict('records'):
                f.write(json.dumps(item, ensure_ascii=False) + '\n')
        
        print(f"  âœ… {folder_name}/data_demo.jsonl: {len(demo_data)} máº«u")

def main():
    parser = argparse.ArgumentParser(description="Chia dá»¯ liá»‡u clickbait tiáº¿ng Viá»‡t")
    parser.add_argument("--input", "-i", default="data/clickbait_dataset_vietnamese.jsonl",
                       help="ÄÆ°á»ng dáº«n file dá»¯ liá»‡u Ä‘áº§u vÃ o")
    parser.add_argument("--output", "-o", default="data",
                       help="ThÆ° má»¥c Ä‘áº§u ra")
    parser.add_argument("--train-ratio", type=float, default=0.7,
                       help="Tá»‰ lá»‡ táº­p train (default: 0.7)")
    parser.add_argument("--val-ratio", type=float, default=0.15,
                       help="Tá»‰ lá»‡ táº­p validation (default: 0.15)")
    parser.add_argument("--test-ratio", type=float, default=0.15,
                       help="Tá»‰ lá»‡ táº­p test (default: 0.15)")
    parser.add_argument("--demo-size", type=int, default=100,
                       help="Sá»‘ máº«u trong file demo (default: 100)")
    
    args = parser.parse_args()
    
    # Kiá»ƒm tra tá»‰ lá»‡
    total_ratio = args.train_ratio + args.val_ratio + args.test_ratio
    if abs(total_ratio - 1.0) > 0.01:
        print(f"âŒ Tá»•ng tá»‰ lá»‡ pháº£i báº±ng 1.0, hiá»‡n táº¡i: {total_ratio}")
        return
    
    print("ğŸš€ Báº¯t Ä‘áº§u chia dá»¯ liá»‡u clickbait tiáº¿ng Viá»‡t")
    print("=" * 60)
    
    # 1. Load vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u
    data, label_field = load_and_analyze_data(args.input)
    if data is None:
        print("âŒ KhÃ´ng thá»ƒ load dá»¯ liá»‡u")
        return
    
    # 2. Chia dá»¯ liá»‡u
    train_data, val_data, test_data = split_data_stratified(
        data, label_field, args.train_ratio, args.val_ratio, args.test_ratio
    )
    
    # 3. LÆ°u dá»¯ liá»‡u
    save_split_data(train_data, val_data, test_data, args.output)
    
    # 4. Táº¡o file demo
    create_data_demo(train_data, val_data, test_data, args.output, args.demo_size)
    
    print("\nğŸ‰ HoÃ n thÃ nh chia dá»¯ liá»‡u!")
    print("=" * 60)
    print("ğŸ“ Cáº¥u trÃºc thÆ° má»¥c Ä‘Æ°á»£c táº¡o:")
    print("data/")
    print("â”œâ”€â”€ train_dtVN/")
    print("â”‚   â”œâ”€â”€ data.jsonl")
    print("â”‚   â”œâ”€â”€ data_demo.jsonl")
    print("â”‚   â””â”€â”€ truth.jsonl")
    print("â”œâ”€â”€ val_dtVN/")
    print("â”‚   â”œâ”€â”€ data.jsonl") 
    print("â”‚   â”œâ”€â”€ data_demo.jsonl")
    print("â”‚   â””â”€â”€ truth.jsonl")
    print("â””â”€â”€ test_dtVN/")
    print("    â”œâ”€â”€ data.jsonl")
    print("    â”œâ”€â”€ data_demo.jsonl")
    print("    â””â”€â”€ truth.jsonl")

if __name__ == "__main__":
    main() 